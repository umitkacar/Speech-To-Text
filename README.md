<div align="center">

# ğŸ¤ Speech-To-Text AI

<img src="https://readme-typing-svg.herokuapp.com?font=Fira+Code&size=32&duration=2800&pause=2000&color=2E9EF7&center=true&vCenter=true&width=940&lines=Real-Time+Speech+Recognition;Powered+by+Google+AI;Multi-Language+Support;Voice+Interactive+System" alt="Typing SVG" />

[![Python](https://img.shields.io/badge/Python-3.7+-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://www.python.org/)
[![Google Cloud](https://img.shields.io/badge/Google%20Cloud-4285F4?style=for-the-badge&logo=google-cloud&logoColor=white)](https://cloud.google.com/speech-to-text)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg?style=for-the-badge)](https://opensource.org/licenses/MIT)
[![Stars](https://img.shields.io/github/stars/umitkacar/Speech-To-Text?style=for-the-badge&logo=github)](https://github.com/umitkacar/Speech-To-Text/stargazers)
[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=for-the-badge)](http://makeapullrequest.com)

<p align="center">
  <a href="#-features">Features</a> â€¢
  <a href="#-quick-start">Quick Start</a> â€¢
  <a href="#-usage">Usage</a> â€¢
  <a href="#-examples">Examples</a> â€¢
  <a href="#-trending-resources">Resources</a> â€¢
  <a href="#-roadmap">Roadmap</a> â€¢
  <a href="#-contributing">Contributing</a>
</p>

</div>

---

## ğŸš€ Features

<table>
<tr>
<td>

### ğŸ¯ Core Capabilities
- ğŸ—£ï¸ **Real-time Speech Recognition** - Instant voice-to-text conversion
- ğŸŒ **Multi-Language Support** - Support for 100+ languages
- ğŸ™ï¸ **Microphone Integration** - Easy device selection and management
- ğŸ”„ **Bidirectional Communication** - Speech-to-Text & Text-to-Speech
- âš¡ **Low Latency** - Optimized for real-time applications
- ğŸ¨ **Multiple APIs** - Google, Azure, AWS support ready
- ğŸ–¥ï¸ **Modern CLI** - Rich terminal UI with Typer & Rich

</td>
<td>

### ğŸ’¡ Advanced Features
- ğŸ§  **AI-Powered** - Google Cloud AI integration
- ğŸ”Š **Noise Cancellation** - Ambient noise adjustment
- ğŸ“Š **Custom Sample Rates** - Configurable audio parameters
- ğŸ§ª **Type Hints** - Full type annotations
- ğŸ›ï¸ **Audio Controls** - ALSA mixer integration
- ğŸ“ **Multiple Outputs** - Text, JSON, structured data
- ğŸ”§ **Modern Tooling** - Hatch, pre-commit, pytest

</td>
</tr>
</table>

---

## ğŸ“¦ Quick Start

### Prerequisites

```bash
# Python 3.7 or higher
python3 --version
```

### Installation

#### ğŸ§ Linux (Ubuntu/Debian)

```bash
# Clone the repository
git clone https://github.com/umitkacar/Speech-To-Text.git
cd Speech-To-Text

# Install Python dependencies
sudo -H pip3 install SpeechRecognition PyAudio pyttsx3

# Install system dependencies
sudo apt-get update
sudo apt-get install -y \
    python3-pyaudio \
    portaudio19-dev \
    libportaudio2 \
    libportaudiocpp0 \
    libasound-dev \
    libasound2 \
    alsa-utils \
    alsa-oss
```

#### ğŸ macOS

```bash
# Install Homebrew dependencies
brew install portaudio

# Install Python packages
pip3 install SpeechRecognition PyAudio pyttsx3
```

#### ğŸªŸ Windows

```bash
# Install Python packages
pip install SpeechRecognition PyAudio pyttsx3
```

> **Note**: On Windows, you may need to install [Visual Studio Build Tools](https://visualstudio.microsoft.com/downloads/) for PyAudio.

For detailed installation instructions, see [INSTALL.md](INSTALL.md).

---

## ğŸ’» Usage

### ğŸš€ Quick Start (CLI)

```bash
# Install the modern CLI
pip install -e .

# Listen once
speech-to-text-ai listen

# Continuous recognition
speech-to-text-ai continuous

# Interactive mode (with voice feedback)
speech-to-text-ai interactive

# List available devices
speech-to-text-ai devices

# Show all commands
speech-to-text-ai --help
```

### ğŸ“– CLI Examples

#### ğŸ§ Single Recognition

```bash
# Basic usage
speech-to-text-ai listen

# Specify language
speech-to-text-ai listen --language tr-TR

# Save to file
speech-to-text-ai listen -l en-US -o transcript.txt

# Custom microphone and timeout
speech-to-text-ai listen --mic "USB Audio" --timeout 30
```

#### ğŸ”„ Continuous Mode

```bash
# Continuous recognition
speech-to-text-ai continuous -l en-US

# Save all results to file
speech-to-text-ai continuous -l tr-TR -o meeting_notes.txt

# Limit to 10 iterations
speech-to-text-ai continuous --max 10
```

#### ğŸ’¬ Interactive Assistant

```bash
# Start interactive mode
speech-to-text-ai interactive -l en-US

# With custom settings
speech-to-text-ai interactive -l tr-TR --mic "Built-in Microphone"
```

### ğŸ Python API

```python
from speech_to_text_ai import SpeechRecognizer, MicrophoneManager, TextToSpeech

# Initialize components
mic_manager = MicrophoneManager(device_name="default")
recognizer = SpeechRecognizer(language="en-US", mic_manager=mic_manager)

# Single recognition
result = recognizer.recognize_once()
if result.success:
    print(f"âœ“ Recognized: {result.text}")
else:
    print(f"âœ— Error: {result.error}")

# Interactive mode with TTS
tts = TextToSpeech()
while True:
    result = recognizer.recognize_once()
    if result.success:
        print(f"You said: {result.text}")
        tts.speak(result.text)
```

### ğŸ“š More Documentation

- [CLI Usage Guide](CLI_USAGE.md) - Complete CLI documentation
- [Installation Guide](INSTALL.md) - Detailed installation instructions
- [Legacy Examples](legacy/) - Original Python scripts (google_api_*.py)

---

## ğŸ¯ Trending Resources (2024-2025)

### ğŸ”¥ Top Speech-to-Text Projects & Libraries

#### Modern AI Models (2024-2025)

| Project | Description | Stars | Tech |
|---------|-------------|-------|------|
| [**Whisper**](https://github.com/openai/whisper) | OpenAI's robust speech recognition (SOTA 2024) | ![Stars](https://img.shields.io/github/stars/openai/whisper?style=social) | PyTorch, Transformers |
| [**Faster Whisper**](https://github.com/guillaumekln/faster-whisper) | Optimized Whisper implementation (4x faster) | ![Stars](https://img.shields.io/github/stars/guillaumekln/faster-whisper?style=social) | CTranslate2 |
| [**Whisper.cpp**](https://github.com/ggerganov/whisper.cpp) | C++ port of Whisper (edge devices) | ![Stars](https://img.shields.io/github/stars/ggerganov/whisper.cpp?style=social) | C++, WASM |
| [**Vosk**](https://github.com/alphacep/vosk-api) | Offline speech recognition (100+ languages) | ![Stars](https://img.shields.io/github/stars/alphacep/vosk-api?style=social) | Kaldi |
| [**SpeechBrain**](https://github.com/speechbrain/speechbrain) | All-in-one speech toolkit | ![Stars](https://img.shields.io/github/stars/speechbrain/speechbrain?style=social) | PyTorch |
| [**Wav2Vec 2.0**](https://github.com/facebookresearch/fairseq) | Meta's self-supervised speech model | ![Stars](https://img.shields.io/github/stars/facebookresearch/fairseq?style=social) | PyTorch |
| [**NeMo ASR**](https://github.com/NVIDIA/NeMo) | NVIDIA's conversational AI toolkit | ![Stars](https://img.shields.io/github/stars/NVIDIA/NeMo?style=social) | PyTorch |

#### Real-Time & Production Ready

| Project | Description | Use Case |
|---------|-------------|----------|
| [**Deepgram SDK**](https://github.com/deepgram/deepgram-python-sdk) | Production-grade ASR API | Enterprise applications |
| [**AssemblyAI**](https://github.com/AssemblyAI/assemblyai-python-sdk) | Modern speech-to-text API | Real-time transcription |
| [**Azure Speech SDK**](https://github.com/Azure-Samples/cognitive-services-speech-sdk) | Microsoft's Speech Services | Cloud integration |
| [**Amazon Transcribe**](https://aws.amazon.com/transcribe/) | AWS speech recognition | Scalable solutions |

#### Specialized & Emerging (2024-2025)

| Project | Innovation | GitHub |
|---------|------------|--------|
| [**Distil-Whisper**](https://github.com/huggingface/distil-whisper) | 6x faster Whisper variant | â­ Trending |
| [**Seamless M4T**](https://github.com/facebookresearch/seamless_communication) | Multilingual speech translation | Meta AI |
| [**MMS (Massively Multilingual Speech)**](https://github.com/facebookresearch/fairseq/tree/main/examples/mms) | 1000+ languages support | Meta Research |
| [**Canary**](https://github.com/NVIDIA/NeMo) | NVIDIA's multilingual ASR | SOTA 2024 |

### ğŸ“ Learning Resources

- ğŸ“š [**Speech Recognition Course**](https://www.deeplearning.ai/courses/natural-language-processing-specialization/) - DeepLearning.AI
- ğŸ¥ [**Whisper Tutorial Series**](https://www.youtube.com/results?search_query=openai+whisper+tutorial+2024) - Latest tutorials
- ğŸ“– [**ASR Papers**](https://paperswithcode.com/task/speech-recognition) - State-of-the-art research
- ğŸ› ï¸ [**Hugging Face Audio**](https://huggingface.co/tasks/automatic-speech-recognition) - Pre-trained models

### ğŸ”§ Development Tools (2024-2025)

- ğŸ›ï¸ [**Audio Processing**](https://github.com/jiaaro/pydub) - Modern audio manipulation
- ğŸšï¸ [**Noise Reduction**](https://github.com/timsainb/noisereduce) - AI-powered noise cancellation
- ğŸ“Š [**Speech Analytics**](https://github.com/tyiannak/pyAudioAnalysis) - Audio feature extraction
- ğŸµ [**Librosa**](https://github.com/librosa/librosa) - Audio analysis library

### â˜ï¸ Cloud Services Comparison (2024-2025)

| Service | Accuracy | Speed | Languages | Free Tier | Best For |
|---------|----------|-------|-----------|-----------|----------|
| **Google Cloud Speech** | â­â­â­â­â­ | Fast | 125+ | 60 min/month | General purpose |
| **Deepgram** | â­â­â­â­â­ | Very Fast | 30+ | $200 credit | Real-time apps |
| **AssemblyAI** | â­â­â­â­â­ | Fast | 15+ | 5 hours | Transcription |
| **Azure Speech** | â­â­â­â­ | Medium | 100+ | 5 hours | Enterprise |
| **Amazon Transcribe** | â­â­â­â­ | Fast | 35+ | 60 min/month | AWS ecosystem |
| **Whisper (Self-hosted)** | â­â­â­â­â­ | Medium | 99 | Free | Privacy-first |

---

## ğŸ“ Project Structure

```
Speech-To-Text/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ speech_to_text_ai/        # Main package
â”‚       â”œâ”€â”€ __init__.py            # Package initialization
â”‚       â”œâ”€â”€ __main__.py            # Entry point
â”‚       â”œâ”€â”€ cli.py                 # CLI interface (Typer)
â”‚       â”œâ”€â”€ core/                  # Core modules
â”‚       â”‚   â”œâ”€â”€ recognizer.py      # Speech recognition engine
â”‚       â”‚   â”œâ”€â”€ microphone.py      # Microphone management
â”‚       â”‚   â””â”€â”€ speaker.py         # Text-to-speech
â”‚       â”œâ”€â”€ config/                # Configuration
â”‚       â”‚   â””â”€â”€ settings.py        # Settings management
â”‚       â””â”€â”€ utils/                 # Utilities
â”‚           â””â”€â”€ logger.py          # Logging setup
â”œâ”€â”€ tests/                         # Test suite
â”‚   â”œâ”€â”€ test_recognizer.py
â”‚   â”œâ”€â”€ test_microphone.py
â”‚   â”œâ”€â”€ test_speaker.py
â”‚   â””â”€â”€ test_config.py
â”œâ”€â”€ legacy/                        # Original Python scripts
â”‚   â”œâ”€â”€ google_api_1.py
â”‚   â”œâ”€â”€ google_api_2.py
â”‚   â””â”€â”€ google_api_3_return.py
â”œâ”€â”€ pyproject.toml                 # Project metadata (Hatch)
â”œâ”€â”€ .pre-commit-config.yaml        # Pre-commit hooks
â”œâ”€â”€ Makefile                       # Development commands
â”œâ”€â”€ README.md                      # This file
â”œâ”€â”€ INSTALL.md                     # Installation guide
â”œâ”€â”€ CLI_USAGE.md                   # CLI documentation
â”œâ”€â”€ CONTRIBUTING.md                # Contribution guidelines
â””â”€â”€ CODE_OF_CONDUCT.md            # Code of conduct
```

## ğŸ› ï¸ Technology Stack

<div align="center">

![Python](https://img.shields.io/badge/Python-3.8+-3776AB?style=for-the-badge&logo=python&logoColor=white)
![Typer](https://img.shields.io/badge/Typer-CLI-009688?style=for-the-badge&logo=python&logoColor=white)
![Rich](https://img.shields.io/badge/Rich-Terminal-FF6B6B?style=for-the-badge&logo=python&logoColor=white)
![Hatch](https://img.shields.io/badge/Hatch-Build-4051B5?style=for-the-badge&logo=python&logoColor=white)
![Google Cloud](https://img.shields.io/badge/Google_Cloud-4285F4?style=for-the-badge&logo=google-cloud&logoColor=white)
![Pytest](https://img.shields.io/badge/Pytest-0A9EDC?style=for-the-badge&logo=pytest&logoColor=white)
![Linux](https://img.shields.io/badge/Linux-FCC624?style=for-the-badge&logo=linux&logoColor=black)

</div>

---

## ğŸ—ºï¸ Roadmap

### 2024 Q4 - 2025 Q1

- [x] âœ… Basic speech recognition
- [x] âœ… Multi-language support
- [x] âœ… Microphone integration
- [ ] ğŸš§ **Whisper integration** (OpenAI SOTA model)
- [ ] ğŸš§ **Real-time streaming** (WebSocket support)
- [ ] ğŸš§ **Docker containerization**
- [ ] ğŸ“‹ **GPU acceleration** (CUDA support)
- [ ] ğŸ“‹ **Web interface** (React dashboard)
- [ ] ğŸ“‹ **API endpoints** (FastAPI/Flask)
- [ ] ğŸ“‹ **Multilingual models** (Seamless M4T)
- [ ] ğŸ“‹ **Speaker diarization** (Who spoke when)
- [ ] ğŸ“‹ **Emotion detection** (Sentiment analysis)

---

## ğŸ”§ Audio Configuration

### Check Available Microphones

```bash
# List all audio devices
python -c "import speech_recognition as sr; print(sr.Microphone.list_microphone_names())"
```

### ALSA Controls (Linux)

```bash
# Open mixer
alsamixer

# Command line mixer
amixer

# Test recording
arecord -l
```

---

## ğŸ¤ Contributing

Contributions are what make the open source community amazing! Any contributions you make are **greatly appreciated**.

1. Fork the Project
2. Create your Feature Branch (`git checkout -b feature/AmazingFeature`)
3. Commit your Changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the Branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

See [CONTRIBUTING.md](CONTRIBUTING.md) for detailed guidelines.

---

## ğŸ“œ License

Distributed under the MIT License. See `LICENSE` for more information.

---

## ğŸŒŸ Star History

[![Star History Chart](https://api.star-history.com/svg?repos=umitkacar/Speech-To-Text&type=Date)](https://star-history.com/#umitkacar/Speech-To-Text&Date)

---

## ğŸ“ Contact & Support

<div align="center">

[![GitHub Issues](https://img.shields.io/badge/Issues-Ask_a_Question-blue?style=for-the-badge&logo=github)](https://github.com/umitkacar/Speech-To-Text/issues)
[![GitHub Discussions](https://img.shields.io/badge/Discussions-Join_Chat-green?style=for-the-badge&logo=github)](https://github.com/umitkacar/Speech-To-Text/discussions)

</div>

---

## ğŸ™ Acknowledgments

- [OpenAI Whisper](https://github.com/openai/whisper) - Inspiration for modern ASR
- [SpeechRecognition](https://github.com/Uberi/speech_recognition) - Core library
- [Google Cloud Speech](https://cloud.google.com/speech-to-text) - API provider
- [PyTTSx3](https://github.com/nateshmbhat/pyttsx3) - Text-to-speech engine

---

<div align="center">

### â­ If this project helped you, please consider giving it a star!

Made with â¤ï¸ by the community

</div>
